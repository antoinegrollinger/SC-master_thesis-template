
@misc{CodePostauxBelge,
  title = {{Code Postaux Belge}},
  abstract = {Description unavailable},
  howpublished = {https://www.odwb.be/explore/dataset/code-postaux-belge/},
  langid = {french},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\E43L8V4C\\table.html}
}

@misc{CommandezVosRepas,
  title = {{Commandez vos repas en ligne | Application de livraison de repas | Uber Eats}},
  howpublished = {https://www.ubereats.com/be/feed},
  langid = {french},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\WQLWUEZK\\feed.html}
}

@misc{Deliveroo,
  title = {{Deliveroo}},
  abstract = {Vos restaurants de quartier pr\^ets pour vous livrer.  Commandez d\`es aujourd'hui !},
  howpublished = {https://deliveroo.be/fr/},
  langid = {french}
}

@misc{doorenChoroplethMapsBelgian2019,
  title = {Choropleth Maps with {{R}} - the {{Belgian}} Edition},
  author = {Dooren, Wouter Van},
  year = {2019},
  month = feb,
  journal = {Wouter Van Dooren},
  abstract = {Dreaded by the yearly quest for the SPSS license code on the university intranet, I switched to R for my statistical work. No regrets so far. You can do wonderful things with R. One of my first successes was being able to draw maps. Many fantastic blogs are already available (for instance here and here) and I doubt I will do better in explaining how it works. The parochial purpose of this blog is to show how it's done with some Belgian data.},
  howpublished = {https://www.woutervandooren.eu/post/20190222\_map\_rstat/},
  langid = {american},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\3PWXY997\\20190222_map_rstat.html}
}

@misc{GatheringInsightsRestaurants,
  title = {Gathering Insights from Restaurants and Menus on {{UberEats}}},
  journal = {Data Science Blog},
  abstract = {Motivation:With Covid19, consumers will likely skew their dining options towards meal delivery vs. in restaurant dining. Restaurants that do open will need to significantly reduce in-restaurant dining traffic to only a few patrons at any given time to limit exposure and spread until a vaccine is de},
  langid = {american},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\AVTJ3QS8\\gathering-insights-from-restaurants-and-menus-on-ubereats.html}
}

@article{hillenWebScrapingFood2019,
  title = {Web Scraping for Food Price Research},
  author = {Hillen, Judith},
  year = {2019},
  month = jan,
  journal = {British Food Journal},
  volume = {121},
  number = {12},
  pages = {3350--3361},
  publisher = {{Emerald Publishing Limited}},
  issn = {0007-070X},
  doi = {10.1108/BFJ-02-2019-0081},
  abstract = {Purpose The purpose of this paper is to discuss web scraping as a method for extracting large amounts of data from online sources. The author wants to raise awareness of the method's potential in the field of food price research, hoping to enable fellow researchers to apply this method. Design/methodology/approach The author explains the technical procedure of web scraping, reviews the existing literature, and identifies areas of application and limitations for food price research. Findings The author finds that web scraping is a promising method to collect customised, high-frequency data in real time, overcoming several limitations of currently used food price data sources. With today's applications mostly focussing on (online) consumer prices, the scope of applications for web scraping broadens as more and more price data are published online. Research limitations/implications To better deal with the technical and legal challenges of web scraping and to exploit its scalability, joint data collection projects in the field of agricultural and food economics should be considered. Originality/value In agricultural and food economics, web scraping as a data collection technique has received little attention. This is one of the first articles to address this topic with particular focus on food price analysis.},
  keywords = {Big Data,Data collection,Digitalization,E-commerce,Food price},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\W8K6QF9E\\Hillen - 2019 - Web scraping for food price research.pdf}
}

@misc{Sciensano,
  type = {{Text}},
  title = {{Sciensano}},
  journal = {sciensano.be},
  abstract = {Toute une vie en bonne sant\'e},
  howpublished = {https://www.sciensano.be/fr/accueil},
  langid = {french}
}

@article{seguraDataCollaborativeConsumption2019,
  title = {Data of Collaborative Consumption in Online Food Delivery Services},
  author = {Segura, Miguel A. and Correa, Juan C.},
  year = {2019},
  month = aug,
  journal = {Data in Brief},
  volume = {25},
  pages = {104007},
  issn = {2352-3409},
  doi = {10.1016/j.dib.2019.104007},
  abstract = {This data article contains data regarding the collaborative consumption that takes place in an Online Food Delivery Platform that connects restaurants owners, and customers who wish to order meals and receive them at home or office. These data are associated with the article ``Evaluation of Collaborative consumption of food delivery services through web mining techniques'' [1]. These data are stored in a comma separated value format; that can be easily downloaded from a Mendeley data repository (https://data.mendeley.com/datasets/m9z9hw4nsc/1).},
  langid = {english},
  keywords = {Collaborative consumption,Google maps,Online food ordering,Traffic conditions,Web scraping},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\DC5GM389\\Segura et Correa - 2019 - Data of collaborative consumption in online food d.pdf}
}

@misc{shiCreateInteractiveMap2021,
  title = {Create {{Interactive Map Applications}} in {{R}} and {{R Shiny}} for {{Exploring Geospatial Data}}},
  author = {Shi, Huajing},
  year = {2021},
  month = mar,
  journal = {Medium},
  abstract = {A Web Application using a Map for Input Selection},
  howpublished = {https://towardsdatascience.com/create-interactive-map-applications-in-r-and-r-shiny-for-exploring-geospatial-data-96b0f9692f0f},
  langid = {english},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\39U5Z7PE\\create-interactive-map-applications-in-r-and-r-shiny-for-exploring-geospatial-data-96b0f9692f0f.html}
}

@misc{TakeawayCom101,
  title = {Takeaway.Com 101: The Essential Guide for Restaurants},
  shorttitle = {Takeaway.Com 101},
  journal = {Deliverect},
  abstract = {If you own a restaurant and you're thinking of signing up with Takeaway.com, here's everything you need to know about this online food delivery platform.},
  howpublished = {https://www.deliverect.com/en/blog/online-food-delivery/takeaway-com-101-the-essential-guide-for-restaurants},
  langid = {english},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\ARJPXHPE\\takeaway-com-101-the-essential-guide-for-restaurants.html}
}

@misc{TakeawayComLivraison,
  title = {Takeaway.Com | {{Livraison}} de Repas \`a Domicile},
  howpublished = {https://www.takeaway.com/be-fr},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\JM5FFAWG\\be-fr.html}
}

@misc{UberEats,
  title = {{Uber Eats}},
  howpublished = {https://www.ubereats.com/be-en/feed},
  langid = {en-BE}
}

@misc{VoorlopigReferentiebestandGemeentegrenzen,
  title = {Voorlopig Referentiebestand Gemeentegrenzen, Toestand 16/05/2018 (Geldig Vanaf 01/01/2019) | {{Datasets}} | {{Catalogus}} | {{Geopunt Vlaanderen}}},
  howpublished = {https://www.geopunt.be/catalogus/datasetfolder/9ff44cc4-5f16-4507-81a6-6810958b14df},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\4J3F2IY9\\9ff44cc4-5f16-4507-81a6-6810958b14df.html}
}

@article{wangHungerHomeDelivery2021,
  title = {Hunger for {{Home Delivery}}: {{Cross-Sectional Analysis}} of the {{Nutritional Quality}} of {{Complete Menus}} on an {{Online Food Delivery Platform}} in {{Australia}}},
  shorttitle = {Hunger for {{Home Delivery}}},
  author = {Wang, Celina and Korai, Andriana and Jia, Si Si and {Allman-Farinelli}, Margaret and Chan, Virginia and Roy, Rajshri and Raeside, Rebecca and Phongsavan, Philayrath and Redfern, Julie and Gibson, Alice A. and Partridge, Stephanie R.},
  year = {2021},
  month = mar,
  journal = {Nutrients},
  volume = {13},
  number = {3},
  pages = {905},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {2072-6643},
  doi = {10.3390/nu13030905},
  abstract = {Online food delivery (OFD) platforms have changed how consumers purchase food prepared outside of home by capitalising on convenience and smartphone technology. Independent food outlets encompass a substantial proportion of partnering outlets, but their offerings' nutritional quality is understudied. Little is also known as to how OFD platforms influence consumer choice. This study evaluated the nutritional quality and marketing attributes of offerings from independent takeaway outlets available on Sydney's market-leading OFD platform (UberEats\textregistered ). Complete menus and marketing attributes from 202 popular outlets were collected using web scraping. All 13841 menu items were classified into 38 food and beverage categories based on the Australian Dietary Guidelines. Of complete menus, 80.5\% (11,139/13,841) were discretionary and 42.3\% (5849/13,841) were discretionary cereal-based mixed meals, the largest of the 38 categories. Discretionary menu items were more likely to be categorised as most popular (OR: 2.5, 95\% CI 1.9\textendash 3.2), accompanied by an image (OR: 1.3, 95\% CI 1.2\textendash 1.5) and offered as a value bundle (OR: 6.5, 95\% CI 4.8\textendash 8.9). Two of the three discretionary food categories were more expensive than their healthier Five Food Group counterparts (p {$<$} 0.02). The ubiquity of discretionary choices offered by independent takeaways and the marketing attributes employed by OFD platforms has implications for public health policy. Further research on the contribution of discretionary choices and marketing attributes to nutritional intakes is warranted.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {adolescent,fast food,food environment,independent outlet,meal deals,nutrition,online food delivery,takeaway foods,young adult},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\G69RVL8R\\Wang et al. - 2021 - Hunger for Home Delivery Cross-Sectional Analysis.pdf;C\:\\Users\\antoi\\Zotero\\storage\\6YP5AM9S\\905.html}
}

@article{WebScraping2022,
  title = {Web Scraping},
  year = {2022},
  month = aug,
  journal = {Wikipedia},
  abstract = {Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites. Web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis. Scraping a web page involves fetching it and extracting from it. Fetching is the downloading of a page (which a browser does when a user views a page). Therefore, web crawling is a main component of web scraping, to fetch pages for later processing. Once fetched, extraction can take place. The content of a page may be parsed, searched and reformatted, and its data copied into a spreadsheet or loaded into a database. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. An example would be finding and copying names and telephone numbers, companies and their URLs, or e-mail addresses to a list (contact scraping). As well as contact scraping, web scraping is used as a component of applications used for web indexing, web mining and data mining, online price change monitoring and price comparison, product review scraping (to watch the competition), gathering real estate listings, weather data monitoring, website change detection, research, tracking online presence and reputation, web mashup, and web data integration. Web pages are built using text-based mark-up languages (HTML and XHTML), and frequently contain a wealth of useful data in text form. However, most web pages are designed for human end-users and not for ease of automated use. As a result, specialized tools and software have been developed to facilitate the scraping of web pages. Newer forms of web scraping involve monitoring data feeds from web servers.  For example, JSON is commonly used as a transport storage mechanism between the client and the web server. There are methods that some websites use to prevent web scraping, such as detecting and disallowing bots from crawling (viewing) their pages. In response, there are web scraping systems that rely on using techniques in DOM parsing, computer vision and natural language processing to simulate human browsing to enable gathering web page content for offline parsing.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1104696547},
  file = {C\:\\Users\\antoi\\Zotero\\storage\\VRE8LCXB\\Web_scraping.html}
}


